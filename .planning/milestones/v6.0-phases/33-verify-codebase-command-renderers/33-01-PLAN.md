---
phase: 33-verify-codebase-command-renderers
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [src/commands/verify.js, src/commands/codebase.js]
autonomous: true
requirements: [CMD-03, CMD-04]

must_haves:
  truths:
    - "verify requirements shows table of requirements with pass/fail status and summary line"
    - "verify quality shows quality dimensions with letter grades and overall score"
    - "codebase status shows formatted summary with staleness indicator"
    - "codebase analyze shows formatted analysis result with mode and file count"
    - "All four commands still produce valid JSON when piped"
  artifacts:
    - path: "src/commands/verify.js"
      provides: "formatVerifyRequirements and formatVerifyQuality formatter functions"
      contains: "formatter"
    - path: "src/commands/codebase.js"
      provides: "formatCodebaseStatus and formatCodebaseAnalyze formatter functions"
      contains: "formatter"
  key_links:
    - from: "src/commands/verify.js"
      to: "src/lib/format.js"
      via: "import formatting primitives"
      pattern: "require.*format"
    - from: "src/commands/codebase.js"
      to: "src/lib/format.js"
      via: "import formatting primitives"
      pattern: "require.*format"
---

<objective>
Add TTY-aware formatted output to 4 user-facing verify/codebase commands: `verify requirements`, `verify quality`, `codebase status`, and `codebase analyze`.

Purpose: Users run these commands to check project health. Formatted output with pass/fail indicators and grades makes results instantly scannable.
Output: Formatter functions wired into output() calls for all 4 commands.
</objective>

<execution_context>
@__OPENCODE_CONFIG__/get-shit-done/workflows/execute-plan.md
@__OPENCODE_CONFIG__/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/30-formatting-foundation-smart-output/30-02-SUMMARY.md
@src/lib/format.js
@src/lib/output.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add formatters to verify requirements and verify quality</name>
  <files>src/commands/verify.js</files>
  <action>
Add `require('../lib/format')` at the top of verify.js — import `banner`, `sectionHeader`, `formatTable`, `summaryLine`, `color`, `SYMBOLS`, `colorByPercent`, `progressBar`, `box`.

**verify requirements (cmdVerifyRequirements):**

Create `formatVerifyRequirements(result)` that renders:
1. `banner('Requirements')` — branded header
2. Summary line: `{addressed}/{total} requirements addressed`
3. `progressBar(addressedPercent)` 
4. If `unaddressed_list` has items: `sectionHeader('Unaddressed')` then `formatTable` with columns [ID, Phase, Reason] where each row shows the unaddressed requirement with `SYMBOLS.cross` prefix on ID
5. If `assertions` exists: `sectionHeader('Assertions')` with `{verified} pass, {failed} fail, {needs_human} needs human` summary
6. `summaryLine(addressedCount === total ? '✓ All requirements addressed' : '{unaddressed} requirements need attention')`

Change `output(result, raw, rawValue)` at line 1190 to:
```js
output(result, { formatter: formatVerifyRequirements, rawValue });
```

**verify quality (cmdVerifyQuality):**

Create `formatVerifyQuality(result)` that renders:
1. `banner('Quality')` — branded header
2. Overall score: `color.bold(grade)` with `colorByPercent(score)` applied, e.g., `A (95/100)`
3. `sectionHeader('Dimensions')` then `formatTable` with columns [Dimension, Score, Weight, Detail] where:
   - Score column uses `colorByPercent` for color
   - Null scores show `color.dim('n/a')`
   - Dimension names: Tests, Must-Haves, Requirements, Regression
4. Trend indicator: `↑ improving`, `→ stable`, or `↓ declining` with appropriate color
5. `summaryLine('Quality: {grade} ({score}/100) — {trend}')`

Change `output({...}, raw)` at line 1758 to:
```js
output({score, grade, dimensions, trend, plan: planId, phase: ...}, { formatter: formatVerifyQuality });
```

IMPORTANT: Do NOT touch any other verify commands — they are agent-consumed.
  </action>
  <verify>Run `node bin/gsd-tools.cjs verify requirements` in terminal — should show table with pass/fail. Run `node bin/gsd-tools.cjs verify quality` — should show dimensions table with grades. Both should produce JSON when piped.</verify>
  <done>verify requirements shows pass/fail table, verify quality shows dimension grades, both produce JSON when piped</done>
</task>

<task type="auto">
  <name>Task 2: Add formatters to codebase status and codebase analyze</name>
  <files>src/commands/codebase.js</files>
  <action>
Add `require('../lib/format')` at the top of codebase.js — import `banner`, `sectionHeader`, `formatTable`, `summaryLine`, `color`, `SYMBOLS`, `box`, `relativeTime`.

**codebase status (cmdCodebaseStatus):**

Create `formatCodebaseStatus(result)` that renders:
1. `banner('Codebase')` — branded header
2. If `!result.exists`: `box('No codebase intel. Run: codebase analyze', 'warning')`
3. If `result.stale`: `box('Intel is stale: {reason}', 'warning')` + `{changed_files.length} files changed` + if `changed_groups`: show added/modified/deleted counts
4. If fresh: show `SYMBOLS.check + ' Intel is fresh'` + `generated_at` as `relativeTime()` + `total_files` files, `languages.length` languages
5. `summaryLine(stale ? 'Stale — run codebase analyze' : 'Fresh')`

Wire into the 3 output() calls in cmdCodebaseStatus (lines ~110, ~126, ~137):
```js
output({...}, { formatter: formatCodebaseStatus });
```

**codebase analyze (cmdCodebaseAnalyze):**

Create `formatCodebaseAnalyze(result)` that renders:
1. `banner('Codebase Analyze')` — branded header
2. Mode indicator: `SYMBOLS.check + ' Analysis complete'` with mode (full/incremental/cached)
3. Stats: `{files_analyzed} files analyzed, {total_files} total` + `{languages.join(', ')}` languages
4. Duration: `{duration_ms}ms`
5. `summaryLine('Analysis complete ({mode})')`

Wire into the 2 output() calls in cmdCodebaseAnalyze (lines ~46-54, ~86-94):
```js
output({...}, { formatter: formatCodebaseAnalyze });
```

IMPORTANT: Do NOT touch any other codebase commands — they are agent-consumed.
  </action>
  <verify>Run `node bin/gsd-tools.cjs codebase status` — should show formatted status. Run `node bin/gsd-tools.cjs codebase analyze` — should show formatted result. Both should produce JSON when piped (`| cat`).</verify>
  <done>codebase status shows staleness indicator and stats, codebase analyze shows mode and file count, both produce JSON when piped</done>
</task>

</tasks>

<verification>
1. `node bin/gsd-tools.cjs verify requirements` — table with pass/fail indicators
2. `node bin/gsd-tools.cjs verify quality` — dimensions with letter grades  
3. `node bin/gsd-tools.cjs codebase status` — formatted staleness indicator
4. `node bin/gsd-tools.cjs codebase analyze` — formatted analysis result
5. All four piped to `| cat` produce valid JSON
6. `npm test` — all existing tests pass
</verification>

<success_criteria>
All 4 user-facing commands produce branded formatted output in TTY and JSON when piped. No regressions.
</success_criteria>

<output>
After completion, create `.planning/phases/33-verify-codebase-command-renderers/33-01-SUMMARY.md`
</output>
