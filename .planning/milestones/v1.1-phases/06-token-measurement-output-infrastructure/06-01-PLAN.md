---
phase: 06-token-measurement-output-infrastructure
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [package.json, package-lock.json, build.js, src/lib/context.js, src/lib/output.js, src/router.js, src/commands/features.js, bin/gsd-tools.test.cjs]
autonomous: true
requirements: [MEAS-01, CLIP-01]

must_haves:
  truths:
    - "Running `context-budget <file>` returns token estimates within 10% of BPE ground truth instead of the broken lines*4 heuristic"
    - "Any JSON-outputting command accepts `--fields name,status,phase` and returns only those fields"
    - "Existing commands without --fields work identically to before (backward compatible)"
    - "npm run build produces a working bundle that includes tokenx (not externalized)"
    - "npm test passes with all existing tests plus new tests for token estimation and --fields"
  artifacts:
    - path: "src/lib/context.js"
      provides: "Token estimation utilities using tokenx"
      contains: "estimateTokens"
    - path: "src/lib/output.js"
      provides: "JSON field filtering support in output()"
      contains: "Fields"
    - path: "build.js"
      provides: "esbuild config that bundles tokenx"
      contains: "external"
    - path: "bin/gsd-tools.test.cjs"
      provides: "Tests for token estimation and --fields filtering"
      contains: "estimateTokens"
  key_links:
    - from: "src/lib/context.js"
      to: "tokenx"
      via: "npm dependency import"
      pattern: "require.*tokenx"
    - from: "src/router.js"
      to: "src/lib/output.js"
      via: "global --fields flag parsed in router, applied in output()"
      pattern: "fields"
    - from: "src/commands/features.js"
      to: "src/lib/context.js"
      via: "context-budget uses estimateTokens"
      pattern: "estimateTokens"
---

<objective>
Install tokenx library for accurate token estimation, create src/lib/context.js module, add --fields flag to all JSON commands, and update context-budget to use real token counting.

Purpose: This is the measurement foundation that all subsequent context reduction depends on. Without accurate token counting, we can't prove the 30% target. Without --fields, Phase 7's --compact flag has no infrastructure to build on. The broken `lines * 4` heuristic in context-budget underestimates by 20-50% and must be replaced.

Output: New context.js module with estimateTokens/estimateJsonTokens/checkBudget, --fields global flag in router.js + output.js, updated context-budget command using tokenx, updated build.js to bundle tokenx, tests.
</objective>

<execution_context>
@__OPENCODE_CONFIG__/get-shit-done/workflows/execute-plan.md
@__OPENCODE_CONFIG__/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/research/SUMMARY.md
@.planning/research/ARCHITECTURE.md
@.planning/phases/06-token-measurement-output-infrastructure/06-CONTEXT.md

@src/lib/output.js
@src/lib/helpers.js
@src/router.js
@src/commands/features.js
@build.js
@package.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install tokenx and create src/lib/context.js</name>
  <files>package.json, package-lock.json, src/lib/context.js, build.js</files>
  <action>
1. Install tokenx as a production dependency (it must be bundled, not external):
   ```
   npm install tokenx@1.3.0
   ```

2. Update `build.js` to bundle tokenx instead of externalizing it. Change the `packages: 'external'` option to only externalize Node.js built-in modules. This is critical — tokenx must be included in the bundle:
   ```javascript
   // BEFORE: packages: 'external',  // Don't bundle node built-ins
   // AFTER:  external: ['node:*', 'child_process', 'fs', 'path', 'os', 'crypto', 'util', 'stream', 'events', 'buffer', 'url', 'querystring', 'http', 'https', 'net', 'tls', 'zlib'],
   ```
   Remove `packages: 'external'` and replace with explicit `external` array listing only Node.js built-in modules that should NOT be bundled. This way tokenx (and any future npm deps) get bundled into the single file.

3. Create `src/lib/context.js` with these exports:
   - `estimateTokens(text)` — uses tokenx's `estimateTokenCount()` for accurate estimation (~96% for prose, ~80-90% for structured content). Falls back to `Math.ceil(text.length / 4)` if tokenx fails.
   - `estimateJsonTokens(obj)` — calls `estimateTokens(JSON.stringify(obj))`
   - `checkBudget(tokens, config)` — returns `{ tokens, percent, warning, recommendation }` using config.context_window and config.context_target_percent
   - `isWithinBudget(text, config)` — convenience: estimate + check in one call

   Import tokenx using: `const { estimateTokenCount } = require('tokenx');`
   If tokenx is ESM-only, esbuild will handle the conversion to CJS automatically.

4. Run `npm run build` to verify the bundle builds successfully with tokenx included. Check the bundle size — should grow from ~257KB to ~262KB (tokenx is 4.5KB).

**Why tokenx over alternatives:** tokenx is 4.5KB bundled with zero deps and ~96% accuracy for prose. gpt-tokenizer is 1.1MB. tiktoken requires WASM. This was decided in research phase (STATE.md decisions).

**Fallback strategy:** If tokenx import fails at runtime (should never happen with bundling), the functions fall back to `Math.ceil(text.length / 4)` with a debugLog warning. This ensures the CLI never crashes due to token estimation.
  </action>
  <verify>
Run:
```
npm run build
node bin/gsd-tools.cjs current-timestamp --raw
```
Build succeeds and smoke test passes. Check bundle includes tokenx:
```
grep -c "estimateTokenCount" bin/gsd-tools.cjs
```
Should be > 0.
  </verify>
  <done>tokenx installed, context.js created with estimateTokens/estimateJsonTokens/checkBudget/isWithinBudget, build.js updated to bundle tokenx, build passes smoke test, bundle size is ~262KB</done>
</task>

<task type="auto">
  <name>Task 2: Add --fields flag to router.js and output.js</name>
  <files>src/router.js, src/lib/output.js, bin/gsd-tools.test.cjs</files>
  <action>
1. In `src/router.js`, parse `--fields` as a global flag before command dispatch (similar to how `--raw` is already parsed):
   ```javascript
   // After the --raw parsing block, add:
   const fieldsIdx = args.indexOf('--fields');
   let requestedFields = null;
   if (fieldsIdx !== -1) {
     requestedFields = args[fieldsIdx + 1] ? args[fieldsIdx + 1].split(',') : null;
     args.splice(fieldsIdx, 2); // Remove --fields and its value from args
   }
   // Store for output.js to use
   if (requestedFields) {
     global._gsdRequestedFields = requestedFields;
   }
   ```

2. In `src/lib/output.js`, update `output()` to apply field filtering before JSON serialization:
   ```javascript
   function output(result, raw, rawValue) {
     if (raw && rawValue !== undefined) {
       process.stdout.write(String(rawValue));
     } else {
       let filtered = result;
       if (global._gsdRequestedFields && typeof result === 'object' && result !== null) {
         filtered = filterFields(result, global._gsdRequestedFields);
       }
       const json = JSON.stringify(filtered, null, 2);
       // ... existing large payload / tmpfile logic
     }
     process.exit(0);
   }
   ```

3. Implement `filterFields(obj, fields)` in output.js:
   - Support dot-notation: `--fields name,phases.status` extracts nested paths
   - For arrays: apply filtering to each element
   - Missing fields: include as `null` (caller knows it was requested but absent)
   - Example: `--fields name,status` on `{name: "foo", status: "ok", extra: "bar"}` returns `{name: "foo", status: "ok"}`
   - Example: `--fields phases.goal` on `{phases: [{goal: "x", other: "y"}]}` returns `{phases: [{goal: "x"}]}`

4. Add tests in `bin/gsd-tools.test.cjs` for --fields:
   - Test basic field filtering (top-level keys)
   - Test dot-notation nested access
   - Test array element filtering
   - Test missing fields return null
   - Test without --fields returns full output (backward compat)

**Implementation note for filterFields:** Keep it simple. Dot-notation means split on ".", walk the object. For arrays, recurse into each element. Don't over-engineer — jmespath-level complexity is not needed. The CONTEXT.md says the agent has discretion on whether --fields affects table output too — for now, only filter JSON output (the primary consumer).

**Global variable pattern:** Using `global._gsdRequestedFields` matches the short-lived CLI process model. The process lives <5s and handles one command. This is the simplest way to pass router-parsed flags to the output function without threading them through every command function signature.
  </action>
  <verify>
Run tests:
```
npm run build && npm test
```
All existing tests pass. New --fields tests pass. Manual verification:
```
node bin/gsd-tools.cjs init progress --fields milestone_version,phase_count --raw 2>/dev/null
```
Returns JSON with only `milestone_version` and `phase_count` fields.
  </verify>
  <done>--fields flag parsed in router.js, filterFields() implemented in output.js with dot-notation and array support, all tests pass including new --fields tests, backward compatible (no --fields = full output)</done>
</task>

<task type="auto">
  <name>Task 3: Update context-budget to use tokenx and add tests</name>
  <files>src/commands/features.js, bin/gsd-tools.test.cjs</files>
  <action>
1. Update `cmdContextBudget()` in `src/commands/features.js` to use the new `estimateTokens` from context.js instead of the broken `lines * 4` heuristic:
   ```javascript
   const { estimateTokens, estimateJsonTokens, checkBudget } = require('../lib/context');
   ```

   Replace all instances of `content.split('\n').length * 4` (the broken heuristic) with `estimateTokens(content)`:
   - `planTokens = estimateTokens(content)` instead of `content.split('\n').length * 4`
   - `fileReadTokens` should sum `estimateTokens(fileContent)` for each file instead of `totalLines * 4`

   Keep the `executionTokens = taskCount * 3500` and `testTokens = taskCount * 750` estimates as-is — those are heuristics for execution overhead, not text token counts.

2. Update the output to include both the tokenx estimate and the old heuristic for comparison:
   Add `heuristic_tokens` field alongside `plan_tokens` and `file_read_tokens` so users can see the difference.

3. Add tests for token estimation accuracy:
   - Test `estimateTokens` on a known text string (compare against expected range)
   - Test `estimateJsonTokens` on a sample JSON object
   - Test `checkBudget` returns correct percent and warning
   - Test `cmdContextBudget` output includes tokenx-based estimates

4. Run the full test suite to ensure nothing is broken.

**Accuracy note:** tokenx is ~96% accurate for prose, ~80-90% for structured content. The 10% accuracy requirement from the success criteria is achievable for typical GSD content (mixed prose and markdown).
  </action>
  <verify>
Run:
```
npm run build && npm test
```
All tests pass. Manual verification:
```
node bin/gsd-tools.cjs context-budget .planning/ROADMAP.md --raw 2>/dev/null | python3 -c "import json,sys; d=json.load(sys.stdin); print(f'plan_tokens: {d[\"estimates\"][\"plan_tokens\"]}, old would be: {d[\"estimates\"].get(\"heuristic_tokens\", \"N/A\")}')"
```
Token count should be meaningfully different from the old `lines * 4` heuristic.
  </verify>
  <done>context-budget uses estimateTokens() from context.js, broken lines*4 heuristic replaced, output includes both new and old estimates for comparison, new tests for estimateTokens/estimateJsonTokens/checkBudget pass, full test suite passes</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npm run build` succeeds (bundle includes tokenx)
- [ ] `npm test` passes (all existing + new tests)
- [ ] `node bin/gsd-tools.cjs context-budget .planning/ROADMAP.md --raw` returns accurate token estimates
- [ ] `node bin/gsd-tools.cjs init progress --fields milestone_version,phase_count --raw` returns filtered JSON
- [ ] `node bin/gsd-tools.cjs init progress --raw` returns full JSON (backward compat)
- [ ] Bundle size is reasonable (~262KB, not >300KB)
</verification>

<success_criteria>
- All tasks completed with passing tests
- tokenx integrated and bundled (not external)
- context-budget uses accurate token estimation, not lines*4
- --fields flag works on any JSON command with dot-notation support
- No regressions in existing functionality
- All verification checks pass
</success_criteria>

<output>
After completion, create `.planning/phases/06-token-measurement-output-infrastructure/06-01-SUMMARY.md`
</output>
